{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4959, -0.6561]])\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_path = \"model/tuned-bert\"\n",
    "tokenizer_path = \"model/tuned-bert-tokenizer\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "def predict(loan_word, original_word):\n",
    "    \"\"\"Predicts if a loanword belongs to the target language.\"\"\"\n",
    "    \n",
    "    encoded_input = tokenizer(\n",
    "        f\"{loan_word} [SEP] {original_word}\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_input[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded_input[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()  # Convert to class label\n",
    "    print(logits)\n",
    "    return predicted_label\n",
    "\n",
    "loan_word = \"हैवान\"\n",
    "original_word = \"بیابان\"\n",
    "\n",
    "predicted_class = predict(loan_word, original_word)\n",
    "print(f\"Prediction: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "language_pairs = [\n",
    "    (\"Azerbaijani\", \"Arabic\"),\n",
    "    (\"Catalan\", \"Arabic\"),\n",
    "    (\"Chinese\", \"English\"),\n",
    "    (\"English\", \"French\"),\n",
    "    (\"English\", \"German\"),\n",
    "    (\"Finnish\", \"Swedish\"),\n",
    "    (\"German\", \"French\"),\n",
    "    (\"German\", \"Italian\"),\n",
    "    (\"Hindi\", \"Persian\"),\n",
    "    (\"Hungarian\", \"German\"),\n",
    "    (\"Indonesian\", \"Dutch\"),\n",
    "    (\"Kazakh\", \"Russian\"),\n",
    "    (\"Persian\", \"Arabic\"),\n",
    "    (\"Polish\", \"French\"),\n",
    "    (\"Romanian\", \"French\"),\n",
    "    (\"Romanian\", \"Hungarian\"),\n",
    "]\n",
    "label_mapping = {\n",
    "    \"random\": 0,\n",
    "    \"hard_negative\": 1,\n",
    "    \"loan\": 0,\n",
    "    \"synonym\": 0\n",
    "}\n",
    "\n",
    "def read_language(lang1, lang2):\n",
    "    file_path = f\"data/production_train_test/{lang1}-{lang2}/balanced/{lang1}-{lang2}-test_production_balanced.csv\"    \n",
    "    if os.path.exists(file_path):  \n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.drop(columns=[col for col in ['Unnamed: 0.1', 'Unnamed: 0'] if col in df.columns], errors=\"ignore\")\n",
    "        df[\"language_pair\"] = f\"{lang1}-{lang2}\"\n",
    "        df[\"label\"] = df[\"label\"].map(label_mapping).astype(int) \n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azerbaijani-Arabic | Accuracy: 0.9732 | F1-score: 0.9722\n",
      "Sample Predictions:\n",
      "  - Loan: məlumat | Original: مَعْلُومَات | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Catalan-Arabic | Accuracy: 0.9444 | F1-score: 0.9175\n",
      "Sample Predictions:\n",
      "  - Loan: moixama | Original: مُشَمَّع | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Chinese-English | Accuracy: 0.9421 | F1-score: 0.9329\n",
      "Sample Predictions:\n",
      "  - Loan: 逆境 | Original: Catastrophe | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "English-French | Accuracy: 0.9202 | F1-score: 0.9062\n",
      "Sample Predictions:\n",
      "  - Loan: gutter rabbit | Original: lapin de gouttière | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "English-German | Accuracy: 0.9116 | F1-score: 0.9116\n",
      "Sample Predictions:\n",
      "  - Loan: Stopp | Original: Stopp | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Finnish-Swedish | Accuracy: 0.9280 | F1-score: 0.9186\n",
      "Sample Predictions:\n",
      "  - Loan: Suru | Original: Förnedring | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "German-French | Accuracy: 0.9154 | F1-score: 0.9074\n",
      "Sample Predictions:\n",
      "  - Loan: Poulet | Original: poulet | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "German-Italian | Accuracy: 0.8800 | F1-score: 0.8800\n",
      "Sample Predictions:\n",
      "  - Loan: Offen | Original: Chiaro | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Hindi-Persian | Accuracy: 0.9157 | F1-score: 0.9061\n",
      "Sample Predictions:\n",
      "  - Loan: ज़बानी | Original: ذره | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Hungarian-German | Accuracy: 0.9074 | F1-score: 0.9136\n",
      "Sample Predictions:\n",
      "  - Loan: Méltóságteljes | Original: Raffiniert | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Indonesian-Dutch | Accuracy: 0.9026 | F1-score: 0.8929\n",
      "Sample Predictions:\n",
      "  - Loan: Pemboros | Original: Overvloedig | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Kazakh-Russian | Accuracy: 0.9478 | F1-score: 0.9410\n",
      "Sample Predictions:\n",
      "  - Loan: винкристин | Original: винкристин | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Persian-Arabic | Accuracy: 0.9279 | F1-score: 0.9155\n",
      "Sample Predictions:\n",
      "  - Loan: حاج | Original: حَاجّ | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Polish-French | Accuracy: 0.9366 | F1-score: 0.9282\n",
      "Sample Predictions:\n",
      "  - Loan: dezaktualizować | Original: désactualiser | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Romanian-French | Accuracy: 0.9298 | F1-score: 0.9208\n",
      "Sample Predictions:\n",
      "  - Loan: Vag | Original: Obscur | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Romanian-Hungarian | Accuracy: 0.9486 | F1-score: 0.9441\n",
      "Sample Predictions:\n",
      "  - Loan: Dămăcuș | Original: Lukács | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "\n",
      " Results saved to `bert_results.csv`\n"
     ]
    }
   ],
   "source": [
    "def predict_batch(loan_words, original_words):\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        [f\"{lw} [SEP] {ow}\" for lw, ow in zip(loan_words, original_words)],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded_inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()  \n",
    "    return predicted_labels, logits.cpu().numpy()\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for lang1, lang2 in language_pairs:\n",
    "    df = read_language(lang1, lang2)\n",
    "    \n",
    "    if df is not None:\n",
    "        y_true = df[\"label\"].values\n",
    "        y_pred, logits = predict_batch(df[\"loan_word\"].tolist(), df[\"original_word\"].tolist())  \n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "        print(f\"{lang1}-{lang2} | Accuracy: {accuracy:.4f} | F1-score: {f1:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Language Pair\": f\"{lang1}-{lang2}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1-score\": f1\n",
    "        })\n",
    "\n",
    "        # Store text-value pairs\n",
    "        text_value_pairs = list(zip(df[\"loan_word\"], df[\"original_word\"], y_pred))\n",
    "        print(\"Sample Predictions:\")\n",
    "        for loan, orig, pred in text_value_pairs[:1]: \n",
    "            print(f\"  - Loan: {loan} | Original: {orig} | Predicted Label: {pred}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"bert_results.csv\", index=False)\n",
    "print(\"\\n Results saved to `bert_results.csv`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Pair</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azerbaijani-Arabic</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.972161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catalan-Arabic</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.917460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese-English</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.932853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English-French</td>\n",
       "      <td>0.920197</td>\n",
       "      <td>0.906185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English-German</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.911565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finnish-Swedish</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.918634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>German-French</td>\n",
       "      <td>0.915441</td>\n",
       "      <td>0.907393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>German-Italian</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hindi-Persian</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.906113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hungarian-German</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.913563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indonesian-Dutch</td>\n",
       "      <td>0.902622</td>\n",
       "      <td>0.892878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kazakh-Russian</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>0.941022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Persian-Arabic</td>\n",
       "      <td>0.927869</td>\n",
       "      <td>0.915464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Polish-French</td>\n",
       "      <td>0.936585</td>\n",
       "      <td>0.928182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romanian-French</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.920814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Romanian-Hungarian</td>\n",
       "      <td>0.948630</td>\n",
       "      <td>0.944104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Language Pair  Accuracy  F1-score\n",
       "0   Azerbaijani-Arabic  0.973214  0.972161\n",
       "1       Catalan-Arabic  0.944444  0.917460\n",
       "2      Chinese-English  0.942105  0.932853\n",
       "3       English-French  0.920197  0.906185\n",
       "4       English-German  0.911565  0.911565\n",
       "5      Finnish-Swedish  0.928000  0.918634\n",
       "6        German-French  0.915441  0.907393\n",
       "7       German-Italian  0.880000  0.880000\n",
       "8        Hindi-Persian  0.915663  0.906113\n",
       "9     Hungarian-German  0.907407  0.913563\n",
       "10    Indonesian-Dutch  0.902622  0.892878\n",
       "11      Kazakh-Russian  0.947802  0.941022\n",
       "12      Persian-Arabic  0.927869  0.915464\n",
       "13       Polish-French  0.936585  0.928182\n",
       "14     Romanian-French  0.929825  0.920814\n",
       "15  Romanian-Hungarian  0.948630  0.944104"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

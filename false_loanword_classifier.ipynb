{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa829b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.meteor_score import meteor_score  # For METEOR score\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a725464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dea37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "class LoanWordClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_phonetic_embeddings, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"model/tuned-bert\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.phonetic_embedder = torch.nn.Embedding(num_phonetic_embeddings, embedding_dim=64)\n",
    "        \n",
    "        bert_hidden_size = self.bert.config.hidden_size \n",
    "        phonetic_size = 64\n",
    "        unicode_size = 25 \n",
    "        other_size = 1\n",
    "        \n",
    "        total_input_size = bert_hidden_size + phonetic_size + unicode_size + other_size\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(total_input_size, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, phonetic_seq, unicode_feature, other_feature):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_states = outputs.last_hidden_state \n",
    "        pooled_output = last_hidden_states.mean(dim=1) \n",
    "        phonetic_emb = self.phonetic_embedder(phonetic_seq).mean(dim=1) \n",
    "\n",
    "    \n",
    "        unicode_feature = unicode_feature.view(unicode_feature.size(0), -1)  \n",
    "        other_feature = other_feature.view(other_feature.size(0), -1)      \n",
    "\n",
    "    \n",
    "        combined = torch.cat([\n",
    "            pooled_output,       \n",
    "            phonetic_emb,        \n",
    "            unicode_feature,     \n",
    "            other_feature        \n",
    "        ], dim=1)               \n",
    "        \n",
    "        logits = self.classifier(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d9c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43664/93288597.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model/loan_word_model.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor([[0.9558, 0.0442]])\n",
      "government tensor([[0.4960, 0.5040]])\n",
      "governed tensor([[0.8994, 0.1006]])\n",
      "a tensor([[0.7115, 0.2885]])\n",
      "new tensor([[0.6860, 0.3140]])\n",
      "abordage tensor([[0.2496, 0.7504]])\n",
      "policy. tensor([[0.6157, 0.3843]])\n",
      "False loan words: ['government', 'abordage']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import epitran\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = LoanWordClassifier(111212)\n",
    "model.load_state_dict(torch.load(\"model/loan_word_model.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained(\"model/tuned-bert-tokenizer\")\n",
    "epi = epitran.Epitran(\"deu-Latn\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def normalize(unicode_values):\n",
    "    mean_value = sum(unicode_values) / len(unicode_values)\n",
    "    return [val - mean_value for val in unicode_values]\n",
    "\n",
    "def extract_features(word, max_len=25):\n",
    "    try:\n",
    "        loan_epitran = epi.transliterate(word)\n",
    "        phonetic_seq = [ord(c) for c in loan_epitran] \n",
    "    except IndexError as e:\n",
    "        print(f\"Transliteration failed for '{word}': {e}\")\n",
    "        phonetic_seq = [0] \n",
    "\n",
    "    unicode_features = [ord(c) for c in word]\n",
    "    unicode_features = normalize(unicode_features)\n",
    "\n",
    "    if len(unicode_features) < max_len:\n",
    "        unicode_features = unicode_features + [0] * (max_len - len(unicode_features))\n",
    "    else:\n",
    "        unicode_features = unicode_features[:max_len]  # Truncate if longer\n",
    "\n",
    "    return phonetic_seq, unicode_features, [len(word)]\n",
    "\n",
    "\n",
    "\n",
    "sentence = \"The government governed a new abordage policy.\"\n",
    "words = sentence.split()\n",
    "\n",
    "false_loans = []\n",
    "for word in words:\n",
    "    phonetic_seq, unicode_feature, other_feature = extract_features(word)\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "            phonetic_seq=torch.tensor([phonetic_seq], dtype=torch.long).to(device),\n",
    "            unicode_feature=torch.tensor([unicode_feature], dtype=torch.float).to(device),\n",
    "            other_feature=torch.tensor([other_feature], dtype=torch.float).to(device)\n",
    "        )\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        print(word , probs)\n",
    "        \n",
    "        if torch.argmax(probs) == 1:  \n",
    "            false_loans.append(word)\n",
    "\n",
    "print(\"False loan words:\", false_loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c55778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2941/2941 [15:55<00:00,  3.08it/s]\n",
      "/tmp/ipykernel_43664/501027761.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['false_loanword_model'] = false_loanwords\n",
      "100%|██████████| 2941/2941 [32:53<00:00,  1.49it/s]\n",
      "/tmp/ipykernel_43664/501027761.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['false_loanword'] = false_loanwords\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "new_df = df[(df['label'] == 'hard_negative') | (df['label'] == 'loan')]\n",
    "\n",
    "def false_loan(sentence):\n",
    "    words = sentence.split()\n",
    "    false_loans = []  \n",
    "    for word in words:\n",
    "        phonetic_seq, unicode_feature, other_feature = extract_features(word)\n",
    "        inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(\n",
    "                input_ids=inputs[\"input_ids\"].to(device),\n",
    "                attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                phonetic_seq=torch.tensor([phonetic_seq], dtype=torch.long).to(device),\n",
    "                unicode_feature=torch.tensor([unicode_feature], dtype=torch.float).to(device),\n",
    "                other_feature=torch.tensor([other_feature], dtype=torch.float).to(device)\n",
    "            )\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            if torch.argmax(probs) == 1: \n",
    "                false_loans.append(word.lower()) \n",
    "    return false_loans\n",
    "\n",
    "false_loanwords = []\n",
    "\n",
    "for _, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    translated_sentence = row['translated_sentence']\n",
    "    result = false_loan(translated_sentence) \n",
    "    false_loanwords.append(result) \n",
    "\n",
    "\n",
    "new_df['false_loanword_model'] = false_loanwords\n",
    "\n",
    "llm = OllamaLLM(model=\"translator\")\n",
    "\n",
    "def false_loanword(sentence):\n",
    "    prompt = f\"\"\"\n",
    "        You are an expert linguistic model. \n",
    "        Given a sentence, identify if there is a **false loanword** (a word that seems borrowed but is wrongly used or misinterpreted).\n",
    "        - If a false loanword is present, output only the false loanword (one word, no explanation).\n",
    "        - If no false loanword is found, output exactly: no\n",
    "        Sentence: {sentence}\n",
    "        Output Response should must contain one single word only\n",
    "        Output Format: Output_word\n",
    "        Do don't include any other thing just give one single word output!\n",
    "    \"\"\"\n",
    "    answer = llm.invoke(prompt)\n",
    "    return answer.strip()\n",
    "\n",
    "false_loanwords = []\n",
    "for _, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    translated_sentence = row['translated_sentence']\n",
    "    result = false_loanword(translated_sentence)\n",
    "    false_loanwords.append(result)\n",
    "new_df['false_loanword'] = false_loanwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b9bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>generated_context</th>\n",
       "      <th>reference_sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>reference_word</th>\n",
       "      <th>label</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mirth</td>\n",
       "      <td>Fröhlichkeit</td>\n",
       "      <td>Die Frau lächelte plötzlich und sagte: \"Ich fü...</td>\n",
       "      <td>The woman smiled suddenly and said, \"I feel ve...</td>\n",
       "      <td>The woman smiled suddenly and said: \"I feel ve...</td>\n",
       "      <td>Cheerfulness</td>\n",
       "      <td>synonym</td>\n",
       "      <td>0.800320</td>\n",
       "      <td>0.905455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schnorr</td>\n",
       "      <td>Chromatogramm</td>\n",
       "      <td>Der Chemiker studierte die Chromatogramme der ...</td>\n",
       "      <td>The chemist studied the chromatograms of the v...</td>\n",
       "      <td>The chemist studied the chromatograms of diffe...</td>\n",
       "      <td>Chromatogram</td>\n",
       "      <td>random</td>\n",
       "      <td>0.582823</td>\n",
       "      <td>0.771560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zettelkasten</td>\n",
       "      <td>Zettelkasten</td>\n",
       "      <td>Ich habe meine Zettelkasten vollgefüllt, um al...</td>\n",
       "      <td>I filled up my paperbox to write down all the ...</td>\n",
       "      <td>I have filled my notebook with all ideas and t...</td>\n",
       "      <td>Paper box</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>0.627753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meiring</td>\n",
       "      <td>Meiring</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>The little dog ran through the forest to look ...</td>\n",
       "      <td>The little dog ran through the woods in search...</td>\n",
       "      <td>Meiring</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.423118</td>\n",
       "      <td>0.721960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speth</td>\n",
       "      <td>Speth</td>\n",
       "      <td>Der Speth fuhr durch die Felder, um frische Ge...</td>\n",
       "      <td>The Speth drove through the fields to buy fres...</td>\n",
       "      <td>The farmer drove through the fields to buy fre...</td>\n",
       "      <td>Speth</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.630807</td>\n",
       "      <td>0.750388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>The little dog ran through the forest to look ...</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>Frankenberger</td>\n",
       "      <td>bleiben lassen</td>\n",
       "      <td>Der Hund bleibt lassen, wenn man ihn nicht füt...</td>\n",
       "      <td>Keep the dog if you don't feed it.</td>\n",
       "      <td>The dog will not leave if you do not feed him.</td>\n",
       "      <td>Keep</td>\n",
       "      <td>hard_negative</td>\n",
       "      <td>0.085166</td>\n",
       "      <td>0.537349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>esteemed</td>\n",
       "      <td>geehrt</td>\n",
       "      <td>Mein Vater gehert mich immer noch.</td>\n",
       "      <td>My father's still insinuating me.</td>\n",
       "      <td>My father still loves me.</td>\n",
       "      <td>Honored</td>\n",
       "      <td>synonym</td>\n",
       "      <td>0.193049</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>Meier</td>\n",
       "      <td>Kauffmann</td>\n",
       "      <td>Der kleine Kaufmann kaufte ein Stück Brot auf ...</td>\n",
       "      <td>The little merchant bought a piece of bread in...</td>\n",
       "      <td>The small merchant bought a loaf of bread on t...</td>\n",
       "      <td>Kauffmann</td>\n",
       "      <td>random</td>\n",
       "      <td>0.178275</td>\n",
       "      <td>0.576994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>aldehyde</td>\n",
       "      <td>Aldehyd</td>\n",
       "      <td>Der Chemiker studierte die Eigenschaften der n...</td>\n",
       "      <td>The chemist studied the properties of the new ...</td>\n",
       "      <td>The chemist studied the properties of the new ...</td>\n",
       "      <td>aldehyde</td>\n",
       "      <td>loan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5294 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_word   original_word  \\\n",
       "0             Mirth    Fröhlichkeit   \n",
       "1           Schnorr   Chromatogramm   \n",
       "2      Zettelkasten    Zettelkasten   \n",
       "3           Meiring         Meiring   \n",
       "4             Speth           Speth   \n",
       "...             ...             ...   \n",
       "5289      Meisinger       Meisinger   \n",
       "5290  Frankenberger  bleiben lassen   \n",
       "5291       esteemed          geehrt   \n",
       "5292          Meier       Kauffmann   \n",
       "5293       aldehyde         Aldehyd   \n",
       "\n",
       "                                      generated_context  \\\n",
       "0     Die Frau lächelte plötzlich und sagte: \"Ich fü...   \n",
       "1     Der Chemiker studierte die Chromatogramme der ...   \n",
       "2     Ich habe meine Zettelkasten vollgefüllt, um al...   \n",
       "3     Der kleine Hund rannte durch den Wald, um nach...   \n",
       "4     Der Speth fuhr durch die Felder, um frische Ge...   \n",
       "...                                                 ...   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...   \n",
       "5290  Der Hund bleibt lassen, wenn man ihn nicht füt...   \n",
       "5291                 Mein Vater gehert mich immer noch.   \n",
       "5292  Der kleine Kaufmann kaufte ein Stück Brot auf ...   \n",
       "5293  Der Chemiker studierte die Eigenschaften der n...   \n",
       "\n",
       "                                     reference_sentence  \\\n",
       "0     The woman smiled suddenly and said, \"I feel ve...   \n",
       "1     The chemist studied the chromatograms of the v...   \n",
       "2     I filled up my paperbox to write down all the ...   \n",
       "3     The little dog ran through the forest to look ...   \n",
       "4     The Speth drove through the fields to buy fres...   \n",
       "...                                                 ...   \n",
       "5289  The little dog ran through the forest to look ...   \n",
       "5290                 Keep the dog if you don't feed it.   \n",
       "5291                  My father's still insinuating me.   \n",
       "5292  The little merchant bought a piece of bread in...   \n",
       "5293  The chemist studied the properties of the new ...   \n",
       "\n",
       "                                    translated_sentence reference_word  \\\n",
       "0     The woman smiled suddenly and said: \"I feel ve...   Cheerfulness   \n",
       "1     The chemist studied the chromatograms of diffe...   Chromatogram   \n",
       "2     I have filled my notebook with all ideas and t...      Paper box   \n",
       "3     The little dog ran through the woods in search...        Meiring   \n",
       "4     The farmer drove through the fields to buy fre...          Speth   \n",
       "...                                                 ...            ...   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...      Meisinger   \n",
       "5290     The dog will not leave if you do not feed him.           Keep   \n",
       "5291                          My father still loves me.        Honored   \n",
       "5292  The small merchant bought a loaf of bread on t...      Kauffmann   \n",
       "5293  The chemist studied the properties of the new ...       aldehyde   \n",
       "\n",
       "              label  bleu_score  meteor_score  \n",
       "0           synonym    0.800320      0.905455  \n",
       "1            random    0.582823      0.771560  \n",
       "2              loan    0.431177      0.627753  \n",
       "3              loan    0.423118      0.721960  \n",
       "4              loan    0.630807      0.750388  \n",
       "...             ...         ...           ...  \n",
       "5289           loan    0.024456      0.000000  \n",
       "5290  hard_negative    0.085166      0.537349  \n",
       "5291        synonym    0.193049      0.300000  \n",
       "5292         random    0.178275      0.576994  \n",
       "5293           loan    1.000000      0.999500  \n",
       "\n",
       "[5294 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f31986e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"model/tuned-bert-tokenizer\")\n",
    "similarity_model = BertModel.from_pretrained(\"model/tuned-bert\")\n",
    "\n",
    "def get_token_embedding(sentence, target_word):\n",
    "    tokens = tokenizer.tokenize(sentence.lower())\n",
    "    token_ids = tokenizer.encode(sentence.lower(), return_tensors=\"pt\")  # Includes [CLS] and [SEP]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = similarity_model(token_ids)\n",
    "    last_hidden_state = outputs.last_hidden_state.squeeze(0)  # Shape: [seq_len, hidden_size]\n",
    "\n",
    "    word_pieces = tokenizer.tokenize(target_word.lower())\n",
    "    indices = [i for i, tok in enumerate(tokens) if tok in word_pieces]\n",
    "\n",
    "    if not indices:\n",
    "        raise ValueError(f\"Word '{target_word}' not found in tokenized sentence: {tokens}\")\n",
    "\n",
    "    embedding = torch.stack([last_hidden_state[i + 1] for i in indices], dim=0).mean(dim=0)\n",
    "    return embedding.detach().numpy()\n",
    "\n",
    "def compare_embeddings(embedding1, embedding2):\n",
    "    return cosine_similarity([embedding1], [embedding2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4256fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2941/2941 [03:32<00:00, 13.83it/s]\n",
      "/tmp/ipykernel_43664/3234542521.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['sim_eng_ger'] = similarity\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "for _, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    translated_sentence = row['translated_sentence'].lower()\n",
    "    generated_context = row['generated_context'].lower()\n",
    "    false_loanword = row[\"false_loanword\"].lower()\n",
    "    original_word = row[\"original_word\"].lower()\n",
    "    if false_loanword != 'false':\n",
    "        try:\n",
    "            embedding_orignal = get_token_embedding(generated_context, original_word)\n",
    "            embedding_eng = get_token_embedding(translated_sentence, false_loanword)\n",
    "            embedding_ger = get_token_embedding(translated_sentence.replace(false_loanword,original_word), original_word)\n",
    "            sim_to_eng = compare_embeddings(embedding_orignal, embedding_eng)\n",
    "            sim_to_ger = compare_embeddings(embedding_orignal, embedding_ger)\n",
    "            similarity.append([sim_to_eng,sim_to_ger])\n",
    "        except ValueError as e:\n",
    "            # print(f\"Error: {e}\")\n",
    "            similarity.append([0,0])\n",
    "        \n",
    "    else:\n",
    "        similarity.append('')\n",
    "new_df['sim_eng_ger'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb837cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>generated_context</th>\n",
       "      <th>reference_sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>reference_word</th>\n",
       "      <th>label</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>false_loanword_model</th>\n",
       "      <th>false_loanword</th>\n",
       "      <th>sim_eng_ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zettelkasten</td>\n",
       "      <td>Zettelkasten</td>\n",
       "      <td>Ich habe meine Zettelkasten vollgefüllt, um al...</td>\n",
       "      <td>I filled up my paperbox to write down all the ...</td>\n",
       "      <td>I have filled my notebook with all ideas and t...</td>\n",
       "      <td>Paper box</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>[notebook]</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meiring</td>\n",
       "      <td>Meiring</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>The little dog ran through the forest to look ...</td>\n",
       "      <td>The little dog ran through the woods in search...</td>\n",
       "      <td>Meiring</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.423118</td>\n",
       "      <td>0.721960</td>\n",
       "      <td>[]</td>\n",
       "      <td>Meiring</td>\n",
       "      <td>[0.42811403, 0.42811403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speth</td>\n",
       "      <td>Speth</td>\n",
       "      <td>Der Speth fuhr durch die Felder, um frische Ge...</td>\n",
       "      <td>The Speth drove through the fields to buy fres...</td>\n",
       "      <td>The farmer drove through the fields to buy fre...</td>\n",
       "      <td>Speth</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.630807</td>\n",
       "      <td>0.750388</td>\n",
       "      <td>[vegetables]</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kaus</td>\n",
       "      <td>cool</td>\n",
       "      <td>Der neue Kühlschrank ist sehr cool.</td>\n",
       "      <td>The new fridge is very cool.</td>\n",
       "      <td>The new refrigerator is very cool.</td>\n",
       "      <td>cool</td>\n",
       "      <td>hard_negative</td>\n",
       "      <td>0.488923</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>[refrigerator]</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nekton</td>\n",
       "      <td>Nekton</td>\n",
       "      <td>Der Nekton schwamm durch die dunklen Gewässer ...</td>\n",
       "      <td>The Nekton swam through the dark waters of the...</td>\n",
       "      <td>The shark swam through the dark waters of the ...</td>\n",
       "      <td>Necton</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.826517</td>\n",
       "      <td>0.905455</td>\n",
       "      <td>[shark, swam]</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>Zimmermann</td>\n",
       "      <td>Zimmermann</td>\n",
       "      <td>Der ehemalige Bundeskanzler Otto von Bismarck ...</td>\n",
       "      <td>The former Chancellor Otto von Bismarck was or...</td>\n",
       "      <td>Der ehemalige Bundeskanzler Otto von Bismarck ...</td>\n",
       "      <td>Carpenter</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.083717</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>[bundeskanzler, otto, bismarck, deutsche, regi...</td>\n",
       "      <td>Zimmermann</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>Hoeffner</td>\n",
       "      <td>Höffner</td>\n",
       "      <td>Der Höffner von der Firma kaufte ein neues Fah...</td>\n",
       "      <td>The Höffner from the company bought a new bicy...</td>\n",
       "      <td>The Höffner from the company bought a new bike...</td>\n",
       "      <td>Höffner</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.500909</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>[it, basket.]</td>\n",
       "      <td>false loanword</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>The little dog ran through the forest to look ...</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[rannte, meisinger-schokoladenladen]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.37442356, 0.8250093]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>Frankenberger</td>\n",
       "      <td>bleiben lassen</td>\n",
       "      <td>Der Hund bleibt lassen, wenn man ihn nicht füt...</td>\n",
       "      <td>Keep the dog if you don't feed it.</td>\n",
       "      <td>The dog will not leave if you do not feed him.</td>\n",
       "      <td>Keep</td>\n",
       "      <td>hard_negative</td>\n",
       "      <td>0.085166</td>\n",
       "      <td>0.537349</td>\n",
       "      <td>[]</td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>aldehyde</td>\n",
       "      <td>Aldehyd</td>\n",
       "      <td>Der Chemiker studierte die Eigenschaften der n...</td>\n",
       "      <td>The chemist studied the properties of the new ...</td>\n",
       "      <td>The chemist studied the properties of the new ...</td>\n",
       "      <td>aldehyde</td>\n",
       "      <td>loan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>[chemist, aldehyde]</td>\n",
       "      <td>False loanword: aldehyde</td>\n",
       "      <td>[0.8589002, 0.8521017]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2941 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_word   original_word  \\\n",
       "2      Zettelkasten    Zettelkasten   \n",
       "3           Meiring         Meiring   \n",
       "4             Speth           Speth   \n",
       "10             Kaus            cool   \n",
       "13           nekton          Nekton   \n",
       "...             ...             ...   \n",
       "5286     Zimmermann      Zimmermann   \n",
       "5288       Hoeffner         Höffner   \n",
       "5289      Meisinger       Meisinger   \n",
       "5290  Frankenberger  bleiben lassen   \n",
       "5293       aldehyde         Aldehyd   \n",
       "\n",
       "                                      generated_context  \\\n",
       "2     Ich habe meine Zettelkasten vollgefüllt, um al...   \n",
       "3     Der kleine Hund rannte durch den Wald, um nach...   \n",
       "4     Der Speth fuhr durch die Felder, um frische Ge...   \n",
       "10                  Der neue Kühlschrank ist sehr cool.   \n",
       "13    Der Nekton schwamm durch die dunklen Gewässer ...   \n",
       "...                                                 ...   \n",
       "5286  Der ehemalige Bundeskanzler Otto von Bismarck ...   \n",
       "5288  Der Höffner von der Firma kaufte ein neues Fah...   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...   \n",
       "5290  Der Hund bleibt lassen, wenn man ihn nicht füt...   \n",
       "5293  Der Chemiker studierte die Eigenschaften der n...   \n",
       "\n",
       "                                     reference_sentence  \\\n",
       "2     I filled up my paperbox to write down all the ...   \n",
       "3     The little dog ran through the forest to look ...   \n",
       "4     The Speth drove through the fields to buy fres...   \n",
       "10                         The new fridge is very cool.   \n",
       "13    The Nekton swam through the dark waters of the...   \n",
       "...                                                 ...   \n",
       "5286  The former Chancellor Otto von Bismarck was or...   \n",
       "5288  The Höffner from the company bought a new bicy...   \n",
       "5289  The little dog ran through the forest to look ...   \n",
       "5290                 Keep the dog if you don't feed it.   \n",
       "5293  The chemist studied the properties of the new ...   \n",
       "\n",
       "                                    translated_sentence reference_word  \\\n",
       "2     I have filled my notebook with all ideas and t...      Paper box   \n",
       "3     The little dog ran through the woods in search...        Meiring   \n",
       "4     The farmer drove through the fields to buy fre...          Speth   \n",
       "10                   The new refrigerator is very cool.           cool   \n",
       "13    The shark swam through the dark waters of the ...         Necton   \n",
       "...                                                 ...            ...   \n",
       "5286  Der ehemalige Bundeskanzler Otto von Bismarck ...      Carpenter   \n",
       "5288  The Höffner from the company bought a new bike...        Höffner   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...      Meisinger   \n",
       "5290     The dog will not leave if you do not feed him.           Keep   \n",
       "5293  The chemist studied the properties of the new ...       aldehyde   \n",
       "\n",
       "              label  bleu_score  meteor_score  \\\n",
       "2              loan    0.431177      0.627753   \n",
       "3              loan    0.423118      0.721960   \n",
       "4              loan    0.630807      0.750388   \n",
       "10    hard_negative    0.488923      0.806667   \n",
       "13             loan    0.826517      0.905455   \n",
       "...             ...         ...           ...   \n",
       "5286           loan    0.083717      0.150000   \n",
       "5288           loan    0.500909      0.744141   \n",
       "5289           loan    0.024456      0.000000   \n",
       "5290  hard_negative    0.085166      0.537349   \n",
       "5293           loan    1.000000      0.999500   \n",
       "\n",
       "                                   false_loanword_model  \\\n",
       "2                                            [notebook]   \n",
       "3                                                    []   \n",
       "4                                          [vegetables]   \n",
       "10                                       [refrigerator]   \n",
       "13                                        [shark, swam]   \n",
       "...                                                 ...   \n",
       "5286  [bundeskanzler, otto, bismarck, deutsche, regi...   \n",
       "5288                                      [it, basket.]   \n",
       "5289               [rannte, meisinger-schokoladenladen]   \n",
       "5290                                                 []   \n",
       "5293                                [chemist, aldehyde]   \n",
       "\n",
       "                false_loanword               sim_eng_ger  \n",
       "2                        false                            \n",
       "3                      Meiring  [0.42811403, 0.42811403]  \n",
       "4                        false                            \n",
       "10                       false                            \n",
       "13                       false                            \n",
       "...                        ...                       ...  \n",
       "5286                Zimmermann                [1.0, 1.0]  \n",
       "5288            false loanword                    [0, 0]  \n",
       "5289                       Der   [0.37442356, 0.8250093]  \n",
       "5290                     false                            \n",
       "5293  False loanword: aldehyde    [0.8589002, 0.8521017]  \n",
       "\n",
       "[2941 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0982ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2941/2941 [11:29<00:00,  4.27it/s]\n",
      "/tmp/ipykernel_43664/284937702.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['similarity_word_eng_ger'] = similarity\n",
      "/tmp/ipykernel_43664/284937702.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['fl_ger'] = fl_ger\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "fl_ger = []\n",
    "\n",
    "for _, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    translated_sentence = row['translated_sentence'].lower()\n",
    "    generated_context = row['generated_context'].lower()     \n",
    "    false_loanwords = row[\"false_loanword_model\"]           \n",
    "    original_word = row[\"original_word\"].lower()             \n",
    "\n",
    "    if isinstance(false_loanwords, str): \n",
    "        false_loanwords = eval(false_loanwords)\n",
    "\n",
    "    if false_loanwords:  \n",
    "        word_similarities = []\n",
    "        higher_german_similarity_words = []\n",
    "        \n",
    "        for false_loanword in false_loanwords:\n",
    "            try:\n",
    "                embedding_original = get_token_embedding(generated_context, original_word)\n",
    "                embedding_eng = get_token_embedding(translated_sentence, false_loanword)\n",
    "                embedding_ger = get_token_embedding(translated_sentence.replace(false_loanword, original_word), original_word)\n",
    "\n",
    "                sim_to_eng = compare_embeddings(embedding_original, embedding_eng)\n",
    "                sim_to_ger = compare_embeddings(embedding_original, embedding_ger)\n",
    "            \n",
    "            except ValueError as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                word_similarities.append([0, 0])\n",
    "                continue\n",
    "            \n",
    "            word_similarities.append([sim_to_eng, sim_to_ger])\n",
    "            \n",
    "\n",
    "            if sim_to_ger > sim_to_eng:\n",
    "                higher_german_similarity_words.append(false_loanword)\n",
    "        \n",
    "        similarity.append(word_similarities)\n",
    "        fl_ger.append(higher_german_similarity_words)\n",
    "    else:\n",
    "        similarity.append([])\n",
    "        fl_ger.append([])\n",
    "\n",
    "\n",
    "new_df['similarity_word_eng_ger'] = similarity\n",
    "new_df['fl_ger'] = fl_ger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd62788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>generated_context</th>\n",
       "      <th>reference_sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>reference_word</th>\n",
       "      <th>label</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>false_loanword_model</th>\n",
       "      <th>false_loanword</th>\n",
       "      <th>sim_eng_ger</th>\n",
       "      <th>similarity_word_eng_ger</th>\n",
       "      <th>fl_ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>enzyme</td>\n",
       "      <td>Enzym</td>\n",
       "      <td>Der Enzym, der die Zucker zu Sauerstoff umwand...</td>\n",
       "      <td>The enzyme that converts sugar into oxygen is ...</td>\n",
       "      <td>Der Enzym, der die Zucker zu Sauerstoff umwand...</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.022870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[zucker]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.7002429, 0.83268857]</td>\n",
       "      <td>[[0.3908607, 0.9491485]]</td>\n",
       "      <td>[zucker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Klees</td>\n",
       "      <td>Klees</td>\n",
       "      <td>Der Kleesmann kümmerte sich um die Reinigung d...</td>\n",
       "      <td>The Kleesmann took care of the cleaning of the...</td>\n",
       "      <td>The translator of the given German sentence is...</td>\n",
       "      <td>Klees</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.048150</td>\n",
       "      <td>0.292245</td>\n",
       "      <td>[kleesmann]</td>\n",
       "      <td>Kleesmann</td>\n",
       "      <td>[0.76906705, 0.6750045]</td>\n",
       "      <td>[[0.76906705, 0.6750045]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pischke</td>\n",
       "      <td>Pischke</td>\n",
       "      <td>Der Pischke im Garten ist sehr groß und hat vi...</td>\n",
       "      <td>The pishke in the garden is very large and has...</td>\n",
       "      <td>The pichk is a type of bird, not an animal tha...</td>\n",
       "      <td>Pishke</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.058166</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>[pichk, an]</td>\n",
       "      <td>pichk</td>\n",
       "      <td>[0.594713, 0.65164655]</td>\n",
       "      <td>[[0.594713, 0.65164655], [0.24290466, 0.692956]]</td>\n",
       "      <td>[pichk, an]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Wermuth</td>\n",
       "      <td>Wermuth</td>\n",
       "      <td>Der kleine Hund ran schnell um den Wermuth herum.</td>\n",
       "      <td>The little dog quickly ran around the wormwood.</td>\n",
       "      <td>The little dog ran quickly around the worm.</td>\n",
       "      <td>Wermuth</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.250986</td>\n",
       "      <td>0.793367</td>\n",
       "      <td>[]</td>\n",
       "      <td>worm</td>\n",
       "      <td>[0.2375343, 0.714456]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Reifsteck</td>\n",
       "      <td>Reifsteck</td>\n",
       "      <td>Der Reifstein war sehr trocken, daher musste i...</td>\n",
       "      <td>The maturation stone was very dry, so I had to...</td>\n",
       "      <td>Der Reifstein war sehr trocken, daher musste i...</td>\n",
       "      <td>Mature plug</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.586233, 0.77951574]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loan_word original_word  \\\n",
       "14     enzyme         Enzym   \n",
       "32      Klees         Klees   \n",
       "46    Pischke       Pischke   \n",
       "54    Wermuth       Wermuth   \n",
       "58  Reifsteck     Reifsteck   \n",
       "\n",
       "                                    generated_context  \\\n",
       "14  Der Enzym, der die Zucker zu Sauerstoff umwand...   \n",
       "32  Der Kleesmann kümmerte sich um die Reinigung d...   \n",
       "46  Der Pischke im Garten ist sehr groß und hat vi...   \n",
       "54  Der kleine Hund ran schnell um den Wermuth herum.   \n",
       "58  Der Reifstein war sehr trocken, daher musste i...   \n",
       "\n",
       "                                   reference_sentence  \\\n",
       "14  The enzyme that converts sugar into oxygen is ...   \n",
       "32  The Kleesmann took care of the cleaning of the...   \n",
       "46  The pishke in the garden is very large and has...   \n",
       "54    The little dog quickly ran around the wormwood.   \n",
       "58  The maturation stone was very dry, so I had to...   \n",
       "\n",
       "                                  translated_sentence reference_word label  \\\n",
       "14  Der Enzym, der die Zucker zu Sauerstoff umwand...         Enzyme  loan   \n",
       "32  The translator of the given German sentence is...          Klees  loan   \n",
       "46  The pichk is a type of bird, not an animal tha...         Pishke  loan   \n",
       "54        The little dog ran quickly around the worm.        Wermuth  loan   \n",
       "58  Der Reifstein war sehr trocken, daher musste i...    Mature plug  loan   \n",
       "\n",
       "    bleu_score  meteor_score false_loanword_model false_loanword  \\\n",
       "14    0.022870      0.000000             [zucker]            Der   \n",
       "32    0.048150      0.292245          [kleesmann]      Kleesmann   \n",
       "46    0.058166      0.122951          [pichk, an]          pichk   \n",
       "54    0.250986      0.793367                   []           worm   \n",
       "58    0.024178      0.000000                   []            Der   \n",
       "\n",
       "                sim_eng_ger                           similarity_word_eng_ger  \\\n",
       "14  [0.7002429, 0.83268857]                          [[0.3908607, 0.9491485]]   \n",
       "32  [0.76906705, 0.6750045]                         [[0.76906705, 0.6750045]]   \n",
       "46   [0.594713, 0.65164655]  [[0.594713, 0.65164655], [0.24290466, 0.692956]]   \n",
       "54    [0.2375343, 0.714456]                                                []   \n",
       "58   [0.586233, 0.77951574]                                                []   \n",
       "\n",
       "         fl_ger  \n",
       "14     [zucker]  \n",
       "32           []  \n",
       "46  [pichk, an]  \n",
       "54           []  \n",
       "58           []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rows = []\n",
    "for _, row in new_df.iterrows():\n",
    "    bleu_score = row['bleu_score']\n",
    "    meteor_score = row['meteor_score']\n",
    "    sim_eng_ger = row['sim_eng_ger']\n",
    "    false_loanword = row['false_loanword']\n",
    "    # Condition 1: BLEU score < 0.5\n",
    "    cond1 = bleu_score < 0.5\n",
    "\n",
    "    # Condition 2: METEOR score < 0.5\n",
    "    cond2 = meteor_score < 0.5\n",
    "\n",
    "    # Condition 3: German embedding similarity is higher ([eng, ger] -> ger > eng)\n",
    "    cond3 = False\n",
    "    if sim_eng_ger and isinstance(sim_eng_ger, list) and len(sim_eng_ger) == 2:\n",
    "        cond3 = sim_eng_ger[1] > sim_eng_ger[0]\n",
    "\n",
    "    # Condition 4: False loanword is an actual word (not \"false\") and matches false_loanword_model\n",
    "    cond4 = false_loanword != 'false' and false_loanword != 'false_loanword'\n",
    "\n",
    "    # Count how many conditions are true\n",
    "    conditions_met = sum([cond1, cond2, cond3, cond4])\n",
    "\n",
    "    if conditions_met >= 3:\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48aa7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows = []\n",
    "for _, row in filtered_df.iterrows():\n",
    "    sim_eng_ger = row['sim_eng_ger']\n",
    "    \n",
    "    # Ensure sim_eng_ger is a list-like structure (e.g., \"[0.2, 0.8]\")\n",
    "    if isinstance(sim_eng_ger, str):\n",
    "        try:\n",
    "            sim_eng_ger = eval(sim_eng_ger)  # Convert string representation of list to actual list\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing sim_eng_ger: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Check if German embedding similarity is higher\n",
    "    if isinstance(sim_eng_ger, list) and len(sim_eng_ger) == 2:\n",
    "        eng_similarity, ger_similarity = sim_eng_ger\n",
    "        if ger_similarity > eng_similarity:\n",
    "            filtered_rows.append(row)\n",
    "            \n",
    "loan_df = pd.DataFrame(filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "747d7ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6579476861167002\n"
     ]
    }
   ],
   "source": [
    "print(len(loan_df)/len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cab7ee59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_word</th>\n",
       "      <th>original_word</th>\n",
       "      <th>generated_context</th>\n",
       "      <th>reference_sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>reference_word</th>\n",
       "      <th>label</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>meteor_score</th>\n",
       "      <th>false_loanword_model</th>\n",
       "      <th>false_loanword</th>\n",
       "      <th>sim_eng_ger</th>\n",
       "      <th>similarity_word_eng_ger</th>\n",
       "      <th>fl_ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>enzyme</td>\n",
       "      <td>Enzym</td>\n",
       "      <td>Der Enzym, der die Zucker zu Sauerstoff umwand...</td>\n",
       "      <td>The enzyme that converts sugar into oxygen is ...</td>\n",
       "      <td>Der Enzym, der die Zucker zu Sauerstoff umwand...</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.022870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[zucker]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.7002429, 0.83268857]</td>\n",
       "      <td>[[0.3908607, 0.9491485]]</td>\n",
       "      <td>[zucker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pischke</td>\n",
       "      <td>Pischke</td>\n",
       "      <td>Der Pischke im Garten ist sehr groß und hat vi...</td>\n",
       "      <td>The pishke in the garden is very large and has...</td>\n",
       "      <td>The pichk is a type of bird, not an animal tha...</td>\n",
       "      <td>Pishke</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.058166</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>[pichk, an]</td>\n",
       "      <td>pichk</td>\n",
       "      <td>[0.594713, 0.65164655]</td>\n",
       "      <td>[[0.594713, 0.65164655], [0.24290466, 0.692956]]</td>\n",
       "      <td>[pichk, an]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Wermuth</td>\n",
       "      <td>Wermuth</td>\n",
       "      <td>Der kleine Hund ran schnell um den Wermuth herum.</td>\n",
       "      <td>The little dog quickly ran around the wormwood.</td>\n",
       "      <td>The little dog ran quickly around the worm.</td>\n",
       "      <td>Wermuth</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.250986</td>\n",
       "      <td>0.793367</td>\n",
       "      <td>[]</td>\n",
       "      <td>worm</td>\n",
       "      <td>[0.2375343, 0.714456]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Reifsteck</td>\n",
       "      <td>Reifsteck</td>\n",
       "      <td>Der Reifstein war sehr trocken, daher musste i...</td>\n",
       "      <td>The maturation stone was very dry, so I had to...</td>\n",
       "      <td>Der Reifstein war sehr trocken, daher musste i...</td>\n",
       "      <td>Mature plug</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.586233, 0.77951574]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Blumenkopf</td>\n",
       "      <td>Blumenkopf</td>\n",
       "      <td>Der Blumenkopf taucht langsam aus dem Wald.</td>\n",
       "      <td>The flower head slowly dives out of the forest.</td>\n",
       "      <td>The Blumenkopf is slowly emerging from the for...</td>\n",
       "      <td>Flower head</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.180444</td>\n",
       "      <td>0.354635</td>\n",
       "      <td>[blumenkopf]</td>\n",
       "      <td>The</td>\n",
       "      <td>[0.37544906, 0.39622292]</td>\n",
       "      <td>[[0.76703185, 0.76703185]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>flehman</td>\n",
       "      <td>flehmen</td>\n",
       "      <td>Der Hund flöhmen konnte nicht mehr, weil er mü...</td>\n",
       "      <td>The dog couldn't flea anymore because he was t...</td>\n",
       "      <td>The dog could no longer cry because he was tired.</td>\n",
       "      <td>Floats</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.403528</td>\n",
       "      <td>0.647131</td>\n",
       "      <td>[]</td>\n",
       "      <td>no</td>\n",
       "      <td>[0.27304706, 0.3717686]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>Bechtel</td>\n",
       "      <td>Der Politiker, der für die Landesregierung kan...</td>\n",
       "      <td>The politician who ran for the state governmen...</td>\n",
       "      <td>The politician who ran for state government wa...</td>\n",
       "      <td>Weight</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.431949</td>\n",
       "      <td>0.663511</td>\n",
       "      <td>[government]</td>\n",
       "      <td>Bechtle</td>\n",
       "      <td>[0.62812185, 0.7227488]</td>\n",
       "      <td>[[0.30271804, 0.6824347]]</td>\n",
       "      <td>[government]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>Roberg</td>\n",
       "      <td>Roberg</td>\n",
       "      <td>Der Tourist fand den Roberg am Strand sehr schön.</td>\n",
       "      <td>The tourist found the Roberg on the beach very...</td>\n",
       "      <td>The tourist found the Robertsgate at the beach...</td>\n",
       "      <td>Roberg</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.350844</td>\n",
       "      <td>0.691837</td>\n",
       "      <td>[beach]</td>\n",
       "      <td>Robertsgate</td>\n",
       "      <td>[0.6308725, 0.7515869]</td>\n",
       "      <td>[[0.2992113, 0.72408533]]</td>\n",
       "      <td>[beach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>Schwaller</td>\n",
       "      <td>Schwaller</td>\n",
       "      <td>Der Schwaller von der Stadt führte mich zum kl...</td>\n",
       "      <td>The swarm from the city led me to the little c...</td>\n",
       "      <td>The Schwaller von der Stadt is likely a misspe...</td>\n",
       "      <td>Swallows</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>[stadt, district, stadt, mich, café,]</td>\n",
       "      <td>Schwabing</td>\n",
       "      <td>[0.59586823, 0.67951965]</td>\n",
       "      <td>[[0.37616584, 0.6403628], [0.16528827, 0.64619...</td>\n",
       "      <td>[stadt, district, stadt, mich, café,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>The little dog ran through the forest to look ...</td>\n",
       "      <td>Der kleine Hund rannte durch den Wald, um nach...</td>\n",
       "      <td>Meisinger</td>\n",
       "      <td>loan</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[rannte, meisinger-schokoladenladen]</td>\n",
       "      <td>Der</td>\n",
       "      <td>[0.37442356, 0.8250093]</td>\n",
       "      <td>[[0.29013312, 0.87097377], [0.827708, 0.820520...</td>\n",
       "      <td>[rannte]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_word original_word  \\\n",
       "14        enzyme         Enzym   \n",
       "46       Pischke       Pischke   \n",
       "54       Wermuth       Wermuth   \n",
       "58     Reifsteck     Reifsteck   \n",
       "72    Blumenkopf    Blumenkopf   \n",
       "...          ...           ...   \n",
       "5256     flehman       flehmen   \n",
       "5261     Bechtel       Bechtel   \n",
       "5276      Roberg        Roberg   \n",
       "5282   Schwaller     Schwaller   \n",
       "5289   Meisinger     Meisinger   \n",
       "\n",
       "                                      generated_context  \\\n",
       "14    Der Enzym, der die Zucker zu Sauerstoff umwand...   \n",
       "46    Der Pischke im Garten ist sehr groß und hat vi...   \n",
       "54    Der kleine Hund ran schnell um den Wermuth herum.   \n",
       "58    Der Reifstein war sehr trocken, daher musste i...   \n",
       "72          Der Blumenkopf taucht langsam aus dem Wald.   \n",
       "...                                                 ...   \n",
       "5256  Der Hund flöhmen konnte nicht mehr, weil er mü...   \n",
       "5261  Der Politiker, der für die Landesregierung kan...   \n",
       "5276  Der Tourist fand den Roberg am Strand sehr schön.   \n",
       "5282  Der Schwaller von der Stadt führte mich zum kl...   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...   \n",
       "\n",
       "                                     reference_sentence  \\\n",
       "14    The enzyme that converts sugar into oxygen is ...   \n",
       "46    The pishke in the garden is very large and has...   \n",
       "54      The little dog quickly ran around the wormwood.   \n",
       "58    The maturation stone was very dry, so I had to...   \n",
       "72      The flower head slowly dives out of the forest.   \n",
       "...                                                 ...   \n",
       "5256  The dog couldn't flea anymore because he was t...   \n",
       "5261  The politician who ran for the state governmen...   \n",
       "5276  The tourist found the Roberg on the beach very...   \n",
       "5282  The swarm from the city led me to the little c...   \n",
       "5289  The little dog ran through the forest to look ...   \n",
       "\n",
       "                                    translated_sentence reference_word label  \\\n",
       "14    Der Enzym, der die Zucker zu Sauerstoff umwand...         Enzyme  loan   \n",
       "46    The pichk is a type of bird, not an animal tha...         Pishke  loan   \n",
       "54          The little dog ran quickly around the worm.        Wermuth  loan   \n",
       "58    Der Reifstein war sehr trocken, daher musste i...    Mature plug  loan   \n",
       "72    The Blumenkopf is slowly emerging from the for...    Flower head  loan   \n",
       "...                                                 ...            ...   ...   \n",
       "5256  The dog could no longer cry because he was tired.         Floats  loan   \n",
       "5261  The politician who ran for state government wa...         Weight  loan   \n",
       "5276  The tourist found the Robertsgate at the beach...         Roberg  loan   \n",
       "5282  The Schwaller von der Stadt is likely a misspe...       Swallows  loan   \n",
       "5289  Der kleine Hund rannte durch den Wald, um nach...      Meisinger  loan   \n",
       "\n",
       "      bleu_score  meteor_score                   false_loanword_model  \\\n",
       "14      0.022870      0.000000                               [zucker]   \n",
       "46      0.058166      0.122951                            [pichk, an]   \n",
       "54      0.250986      0.793367                                     []   \n",
       "58      0.024178      0.000000                                     []   \n",
       "72      0.180444      0.354635                           [blumenkopf]   \n",
       "...          ...           ...                                    ...   \n",
       "5256    0.403528      0.647131                                     []   \n",
       "5261    0.431949      0.663511                           [government]   \n",
       "5276    0.350844      0.691837                                [beach]   \n",
       "5282    0.011525      0.031646  [stadt, district, stadt, mich, café,]   \n",
       "5289    0.024456      0.000000   [rannte, meisinger-schokoladenladen]   \n",
       "\n",
       "     false_loanword               sim_eng_ger  \\\n",
       "14              Der   [0.7002429, 0.83268857]   \n",
       "46            pichk    [0.594713, 0.65164655]   \n",
       "54             worm     [0.2375343, 0.714456]   \n",
       "58              Der    [0.586233, 0.77951574]   \n",
       "72              The  [0.37544906, 0.39622292]   \n",
       "...             ...                       ...   \n",
       "5256             no   [0.27304706, 0.3717686]   \n",
       "5261        Bechtle   [0.62812185, 0.7227488]   \n",
       "5276    Robertsgate    [0.6308725, 0.7515869]   \n",
       "5282      Schwabing  [0.59586823, 0.67951965]   \n",
       "5289            Der   [0.37442356, 0.8250093]   \n",
       "\n",
       "                                similarity_word_eng_ger  \\\n",
       "14                             [[0.3908607, 0.9491485]]   \n",
       "46     [[0.594713, 0.65164655], [0.24290466, 0.692956]]   \n",
       "54                                                   []   \n",
       "58                                                   []   \n",
       "72                           [[0.76703185, 0.76703185]]   \n",
       "...                                                 ...   \n",
       "5256                                                 []   \n",
       "5261                          [[0.30271804, 0.6824347]]   \n",
       "5276                          [[0.2992113, 0.72408533]]   \n",
       "5282  [[0.37616584, 0.6403628], [0.16528827, 0.64619...   \n",
       "5289  [[0.29013312, 0.87097377], [0.827708, 0.820520...   \n",
       "\n",
       "                                     fl_ger  \n",
       "14                                 [zucker]  \n",
       "46                              [pichk, an]  \n",
       "54                                       []  \n",
       "58                                       []  \n",
       "72                                       []  \n",
       "...                                     ...  \n",
       "5256                                     []  \n",
       "5261                           [government]  \n",
       "5276                                [beach]  \n",
       "5282  [stadt, district, stadt, mich, café,]  \n",
       "5289                               [rannte]  \n",
       "\n",
       "[327 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bbd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('Modelfiles/wrong.csv',index=False)\n",
    "loan_df.to_csv('Modelfiles/misclassified.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "095529d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eaba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
